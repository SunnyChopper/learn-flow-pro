// System
import { ZodTypeAny } from "zod";

// Langchain
import { StructuredOutputParser } from "langchain/output_parsers";
import { ChatPromptTemplate } from "langchain/prompts";

export const MAX_TOKENS: number = 2048;
export const FREQUENCY_PENALTY_BASE: number = 0.025;
export const PRESENCE_PENALTY_BASE: number = 0.05;

export interface LLMMode {
    temperature: number;
    maxTokens: number;
    frequencyPenalty: number;
    presencePenalty: number;
}

export const LLM_MODES: { [key: string]: LLMMode } = {
    "creative": {
        temperature: 1,
        maxTokens: MAX_TOKENS,
        frequencyPenalty: FREQUENCY_PENALTY_BASE * 10,
        presencePenalty: PRESENCE_PENALTY_BASE * 10
    },
    "balanced": {
        temperature: 0.7,
        maxTokens: MAX_TOKENS,
        frequencyPenalty: FREQUENCY_PENALTY_BASE * 5,
        presencePenalty: PRESENCE_PENALTY_BASE * 5
    },
    "precise": {
        temperature: 0.5,
        maxTokens: MAX_TOKENS,
        frequencyPenalty: FREQUENCY_PENALTY_BASE,
        presencePenalty: PRESENCE_PENALTY_BASE
    },
    "robotic": {
        temperature: 0.1,
        maxTokens: MAX_TOKENS,
        frequencyPenalty: 0.0,
        presencePenalty: 0.0
    }
}


export default interface LLMService {
    generateResponse(prompt: ChatPromptTemplate, inputs: object, outputParser?: StructuredOutputParser<ZodTypeAny>): Promise<any>;
}