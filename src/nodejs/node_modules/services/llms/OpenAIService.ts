// System
import { ZodAny } from "zod";

// Langchain
import { StructuredOutputParser, OutputFixingParser } from "langchain/output_parsers";
import { ChatOpenAI } from "langchain/chat_models/openai";
import { ChatPromptTemplate } from "langchain/prompts";
import { ChainValues } from "langchain/dist/schema";
import { LLMChain } from "langchain/chains";

// Services
import LLMService, { LLM_MODES } from "./LLMService";

class OpenAIService implements LLMService {
    private chat: ChatOpenAI;
    private mode: string;
    private model: string;

    constructor(model: string = "gpt-3.5-turbo", mode: string = "creative", openAIApiKey: string) {
        this.mode = mode;
        this.model = model;

        this.chat = new ChatOpenAI({ modelName: this.model, openAIApiKey: openAIApiKey, ...LLM_MODES[this.mode] });
    }

    public async generateResponse(prompt: ChatPromptTemplate, inputs: object, outputParser?: StructuredOutputParser<ZodAny>): Promise<any> {
        let answerFormatChain: LLMChain = new LLMChain({
            llm: this.chat,
            prompt: prompt,
            outputParser: outputParser ? OutputFixingParser.fromLLM(this.chat, outputParser) : undefined
        });

        let result: ChainValues;
        try {
            result = await answerFormatChain.call(inputs);
        } catch (error) {
            console.log("ðŸš€ ~ file: OpenAIService.ts:55 ~ OpenAIService ~ generateResponse ~ error:", error);
            throw error;
        }

        return result.text;
    }
}

export default OpenAIService;